{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear algebra: Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "To check every exercise here, import all libraries first, and then, run all codes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor transposition\n",
    "\n",
    "Tensor transposition is the action of changing the rows and columns over the main diagonal of a matrix.\n",
    "\n",
    "$$\n",
    "(X^{T})_{i,j} = X_{j,i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25,  2],\n",
       "        [ 5, 26],\n",
       "        [ 3,  7]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix declaration\n",
    "X = pt.tensor([[25,2], [5, 26], [3, 7]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25,  5,  3],\n",
       "        [ 2, 26,  7]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix tranposition\n",
    "X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tensor arithmetic operations\n",
    "\n",
    "Adding or multiplying with scalars applies the operation to all elements in the matrix and its shape is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28,  5],\n",
       "        [ 8, 29],\n",
       "        [ 6, 10]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "X + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, -3],\n",
       "        [ 0, 21],\n",
       "        [-2,  2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction\n",
    "X - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50,  4],\n",
       "        [10, 52],\n",
       "        [ 6, 14]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "X * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.5000,  1.0000],\n",
       "        [ 2.5000, 13.0000],\n",
       "        [ 1.5000,  3.5000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "X / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, you can use embedded functions to make arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: tensor([[28,  5],\n",
      "        [ 8, 29],\n",
      "        [ 6, 10]])\n",
      "Subtraction: tensor([[20, -3],\n",
      "        [ 0, 21],\n",
      "        [-2,  2]])\n",
      "Multiplication: tensor([[50,  4],\n",
      "        [10, 52],\n",
      "        [ 6, 14]])\n",
      "Division: tensor([[12.5000,  1.0000],\n",
      "        [ 2.5000, 13.0000],\n",
      "        [ 1.5000,  3.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Addition: {pt.add(X, 3)}\")\n",
    "print(f\"Subtraction: {pt.sub(X, 5)}\")\n",
    "print(f\"Multiplication: {pt.mul(X, 2)}\")\n",
    "print(f\"Division: {pt.div(X, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadamard product\n",
    "\n",
    "The Hadamard or element-wise product occurs when two matrices with the same shape apply addition or multiplication operations, it denotes the \"odot\" symbol.\n",
    "$$\n",
    "A \\odot X\n",
    "$$\n",
    "Every element operates with the element in the other matrix in the same position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pt.tensor([[1, 2], [3, 4]])\n",
    "X = pt.tensor([[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  8],\n",
       "        [10, 12]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 12],\n",
       "        [21, 32]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor reduction\n",
    "\n",
    "Calculating the sum across all elements of a tensor is a common operation. For example\n",
    "- For vector **x** of length *n*, we calculate $\\sum^{n}_{i=1}x_i$\n",
    "- for matrix **X** with *m* by *n* dimensions, we calculate $\\sum^{m}_{i=1}\\sum^{n}_{i=1}X_{i,j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Vector\n",
    "x = pt.tensor([1, 2, 3])\n",
    "print(x)\n",
    "# Matrix\n",
    "X = pt.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector reduction\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix reduction\n",
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If only want to reduce the matrix in one dimension, we can select which to reduce, a row or a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 15, 18])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduction along columns (axis 0)\n",
    "X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 15, 24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduction along rows (axis 1)\n",
    "X.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations along matrices\n",
    "\n",
    "Other operations can be applied with reduction along all or a selection of axes, e.g.:\n",
    "- Maximun\n",
    "- Minimu\n",
    "- Mean\n",
    "- Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "torch.return_types.max(\n",
      "values=tensor([7, 8, 9]),\n",
      "indices=tensor([2, 2, 2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([3, 6, 9]),\n",
      "indices=tensor([2, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "# Maximum operation\n",
    "print(X.max()) # Maximum value in the matrix\n",
    "print(X.max(axis=0)) # Maximum value in each column\n",
    "print(X.max(axis=1)) # Maximum value in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "torch.return_types.min(\n",
      "values=tensor([1, 2, 3]),\n",
      "indices=tensor([0, 0, 0]))\n",
      "torch.return_types.min(\n",
      "values=tensor([1, 4, 7]),\n",
      "indices=tensor([0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# Minimum operation\n",
    "print(X.min()) # Maximum value in the matrix\n",
    "print(X.min(axis=0)) # Maximum value in each column\n",
    "print(X.min(axis=1)) # Maximum value in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "tensor([4., 5., 6.])\n",
      "tensor([2., 5., 8.])\n"
     ]
    }
   ],
   "source": [
    "# Mean operation\n",
    "\n",
    "# Mean function in PyTorch works with float or complex values\n",
    "print(pt.mean(X, dtype=pt.float32))\n",
    "print(pt.mean(X, axis=0, dtype=pt.float32))\n",
    "print(pt.mean(X, axis=1, dtype=pt.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(362880)\n",
      "tensor([ 28,  80, 162])\n",
      "tensor([  6, 120, 504])\n"
     ]
    }
   ],
   "source": [
    "# Product operation\n",
    "print(pt.prod(X))\n",
    "print(pt.prod(X, axis=0))\n",
    "print(pt.prod(X, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product\n",
    "\n",
    "If we have two vectors (<strong>*x*</strong> and <strong>*y*</strong>) with the same length *n*, we can calculate the dot product between them. This is annotated several different ways, including the following:\n",
    "- $x \\cdot y$\n",
    "- $x^T y$\n",
    "- $\\left< x,y\\right>$\n",
    "\n",
    "Regardless which notation you use, the calculation is the same; we calculate products in an element-wise fashion and then sum reductively across the products to a scalar value. That is, $x \\cdot y = \\sum^{n}_{i=1}x_{i}y_{i}$\n",
    "\n",
    "The dot product is ubiquitous in deep learning: it is performed at every artificial neuron in a deep neural network, which may be made up of millions of these neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Vectors\n",
    "\n",
    "vec1 = pt.tensor([1, 2, 3])\n",
    "vec2 = pt.tensor([4, 5, 6])\n",
    "\n",
    "print(vec1)\n",
    "print(vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product on vectors\n",
    "pt.dot(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. What is $Y^T$\n",
    "$$\n",
    "Y = \n",
    "\\left(\\begin{array}{}\n",
    "42 & 4 & 7 & 99\\\\\n",
    "-99 & -3 & 17 & 22\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "2. What is the hadamard product of these matrices?\n",
    "$$\n",
    "\\left(\\begin{array}{}\n",
    "25 & 10\\\\\n",
    "-2 & 1\n",
    "\\end{array}\\right)\n",
    "\n",
    "\\odot\n",
    "\n",
    "\\left(\\begin{array}{}\n",
    "-1 & 7\\\\\n",
    "10 & 8\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "3. What is the dot product of the tensors ***w*** and ***x***\n",
    "\n",
    "$$\n",
    "w =\n",
    "\\left(\\begin{array}{}\n",
    "-1 & 2 & -2\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "$$\n",
    "x =\n",
    "\\left(\\begin{array}{}\n",
    "5 & 10 & 0\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 42, -99],\n",
       "        [  4,  -3],\n",
       "        [  7,  17],\n",
       "        [ 99,  22]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.- Transpose Y\n",
    "\n",
    "Y = pt.tensor([[42, 4, 7, 99], [-99, -3 , 17, 22]]) # Matrix declaration\n",
    "Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-25,  70],\n",
       "        [-20,   8]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.- Hadamard product\n",
    "\n",
    "A = pt.tensor([[25, 10], [-2, 1]])\n",
    "B = pt.tensor([[-1, 7], [10, 8]])\n",
    "\n",
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.- Dot product\n",
    "\n",
    "w = pt.tensor([-1, 2, -2])\n",
    "x = pt.tensor([5, 10, 0])\n",
    "\n",
    "pt.dot(w, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
